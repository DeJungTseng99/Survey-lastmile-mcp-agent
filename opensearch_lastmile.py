import asyncio
import time
import re
from typing import List, Any, Optional

from pydantic import BaseModel, Field

from mcp_agent.app import MCPApp
from time_parser import TimeParser, create_time_aware_prompt
from mcp_agent.config import (
    GoogleSettings,
    Settings,
    LoggerSettings,
    MCPSettings,
    MCPServerSettings,
)
from mcp_agent.agents.agent import Agent
from mcp_agent.workflows.llm.augmented_llm_google import GoogleAugmentedLLM


class SecurityEventReport(BaseModel):
    """è³‡å®‰äº‹ä»¶åˆ†æå ±å‘Š"""
    query: str = Field(default="æœªçŸ¥æŸ¥è©¢", description="åŸå§‹æŸ¥è©¢èªå¥")
    total_hits: int = Field(default=0, description="æ‰¾åˆ°çš„è¨˜éŒ„ç¸½æ•¸")
    event_time: str = Field(default="æœªçŸ¥æ™‚é–“", description="äº‹ä»¶ç™¼ç”Ÿæ™‚é–“ (YYYY-MM-DD HH:mm:ss)")
    event_type: str = Field(default="æœªçŸ¥äº‹ä»¶", description="äº‹ä»¶é¡å‹ï¼Œå¦‚ï¼šç™»å…¥å¤±æ•—ã€æª”æ¡ˆåˆªé™¤ã€ç•°å¸¸æµé‡")
    severity: str = Field(default="ä¸­", description="åš´é‡æ€§ï¼šä½/ä¸­/é«˜")
    username: str = Field(default="æœªçŸ¥ä½¿ç”¨è€…", description="ç™¼ç”Ÿäº‹ä»¶çš„å¸³è™Ÿ")
    hostname: str = Field(default="æœªçŸ¥ä¸»æ©Ÿ", description="ç™¼ç”Ÿäº‹ä»¶çš„è¨­å‚™åç¨±")
    host_ip: str = Field(default="æœªçŸ¥IP", description="ç™¼ç”Ÿäº‹ä»¶çš„ IP")
    description: str = Field(default="ç„¡æè¿°", description="äº‹ä»¶è©³ç´°æè¿°")
    recommended_actions: List[str] = Field(default=[], description="å»ºè­°æ¡å–çš„è¡Œå‹•")
    log_samples: List[str] = Field(default=[], description="2-3æ¢å…·ä»£è¡¨æ€§çš„æ—¥èªŒå…§å®¹")


def get_security_status_indicator(severity: str, total_hits: int) -> str:
    """æ ¹æ“šåš´é‡ç¨‹åº¦å’Œè¨˜éŒ„æ•¸é‡è¿”å›å®‰å…¨ç‹€æ…‹æŒ‡ç¤ºå™¨"""
    severity_lower = severity.lower()
    
    if severity_lower == "é«˜" or total_hits > 100:
        return "ğŸ”´ é«˜é¢¨éšªè­¦ç¤º"
    elif severity_lower == "ä¸­" or total_hits > 10:
        return "ğŸŸ¡ ä¸­åº¦è­¦ç¤º"
    elif severity_lower == "ä½" or total_hits > 0:
        return "ğŸŸ  ä½åº¦è­¦ç¤º"
    else:
        return "âœ… å®‰å…¨ç‹€æ…‹"


def format_log_sample(log_sample: str, max_lines: int = 10) -> str:
    """æ ¼å¼åŒ–æ—¥èªŒæ¨£æœ¬ï¼Œé™åˆ¶é¡¯ç¤ºè¡Œæ•¸"""
    try:
        import json
        # å˜—è©¦æ ¼å¼åŒ– JSON
        parsed = json.loads(log_sample)
        formatted = json.dumps(parsed, indent=2, ensure_ascii=False)
        lines = formatted.split('\n')
        if len(lines) > max_lines:
            return '\n'.join(lines[:max_lines]) + '\n  ...(å·²æˆªæ–·)'
        return formatted
    except:
        # å¦‚æœä¸æ˜¯ JSONï¼Œç›´æ¥è¿”å›
        return log_sample


settings = Settings(
    execution_engine="asyncio",
    logger=LoggerSettings(type="console", level="debug"),
    mcp=MCPSettings(
        servers={
            "opensearch": MCPServerSettings(
                transport="streamable_http",
                url="http://localhost:9900/mcp",
                headers={
                    "Accept": "application/json, text/event-stream",
                    "Content-Type": "application/json"
                },
                description="OpenSearch MCP Server for data querying"
            ),
        }
    ),
    google=GoogleSettings(
        default_model="gemini-2.0-flash",
    ),
)

# ä½¿ç”¨é…ç½®æª”æ¡ˆè€Œä¸æ˜¯ç¨‹å¼åŒ–è¨­å®šï¼Œé€™æ¨£æ‰èƒ½è®€å–secrets
app = MCPApp(name="opensearch_agent")


async def test_connection():
    """Test connection to OpenSearch MCP server and list available tools"""
    async with app.run() as agent_app:
        logger = agent_app.logger
        context = agent_app.context

        logger.info("Testing connection to OpenSearch MCP server...")
        print("\n=== æ¸¬è©¦OpenSearch MCPé€£ç·š ===")

        opensearch_agent = Agent(
            name="opensearch_tester",
            instruction="Test agent for connection verification",
            server_names=["opensearch"],
        )

        try:
            async with opensearch_agent:
                logger.info("opensearch_tester: å˜—è©¦é€£æ¥åˆ°MCP server...")
                print("âœ… æˆåŠŸå»ºç«‹èˆ‡OpenSearch MCP serverçš„é€£ç·š")
                
                # List available tools
                tools_result = await opensearch_agent.list_tools()
                logger.info("Tools discovered:", data=tools_result.model_dump())
                
                print(f"\nğŸ“‹ ç™¼ç¾ {len(tools_result.tools)} å€‹å¯ç”¨å·¥å…·:")
                for i, tool in enumerate(tools_result.tools, 1):
                    print(f"   {i}. {tool.name}")
                    if tool.description:
                        print(f"      æè¿°: {tool.description[:100]}...")
                
                # List available prompts
                try:
                    prompts_result = await opensearch_agent.list_prompts()
                    print(f"\nğŸ“ ç™¼ç¾ {len(prompts_result.prompts)} å€‹å¯ç”¨æç¤º:")
                    for i, prompt in enumerate(prompts_result.prompts, 1):
                        print(f"   {i}. {prompt.name}")
                        if prompt.description:
                            print(f"      æè¿°: {prompt.description}")
                except Exception as e:
                    print(f"âš ï¸ ç„¡æ³•åˆ—å‡ºæç¤º: {e}")
                
                return tools_result
                
        except Exception as e:
            logger.error(f"é€£ç·šå¤±æ•—: {e}")
            print(f"âŒ é€£ç·šå¤±æ•—: {e}")
            return None


async def example_usage():
    async with app.run() as agent_app:
        logger = agent_app.logger
        context = agent_app.context

        logger.info("Current config:", data=context.config.model_dump())

        opensearch_agent = Agent(
            name="opensearch_searcher",
            instruction="""You are an OpenSearch query agent with access to search capabilities. Please respond in Traditional Chinese (ç¹é«”ä¸­æ–‡).
            ä½ æ˜¯ä¸€å€‹OpenSearchæŸ¥è©¢åŠ©æ‰‹ï¼Œå…·æœ‰æœå°‹åŠŸèƒ½ã€‚è«‹ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰ã€‚
            Your job is to (ä½ çš„å·¥ä½œæ˜¯):
            1. Understand user search requests and translate them into appropriate OpenSearch queries (ç†è§£ä½¿ç”¨è€…çš„æœå°‹è«‹æ±‚ä¸¦è½‰æ›ç‚ºé©ç•¶çš„OpenSearchæŸ¥è©¢)
            2. Execute the search using available tools (ä½¿ç”¨å¯ç”¨å·¥å…·åŸ·è¡Œæœå°‹)
            3. Generate proper JSON-RPC 2.0 tool calls to the OpenSearch server (ç”Ÿæˆæ­£ç¢ºçš„JSON-RPC 2.0å·¥å…·å‘¼å«)
            4. Format and summarize the search results for the user (ç‚ºä½¿ç”¨è€…æ ¼å¼åŒ–å’Œç¸½çµæœå°‹çµæœ)
            5. Ask for clarification if the search query is ambiguous (å¦‚æœæœå°‹æŸ¥è©¢ä¸æ˜ç¢ºè«‹è¦æ±‚æ¾„æ¸…)
            
            OpenSearch DSL Query Guidelines (OpenSearch DSL æŸ¥è©¢æŒ‡å—):
            
            1. Use term queries for exact matches (ç²¾ç¢ºåŒ¹é…ä½¿ç”¨ term æŸ¥è©¢)
            2. Use match queries for text search (æ–‡å­—æœå°‹ä½¿ç”¨ match æŸ¥è©¢) 
            3. Use bool queries to combine conditions (ä½¿ç”¨ bool æŸ¥è©¢çµ„åˆæ¢ä»¶)
            4. Use range queries for time/numeric filters (æ™‚é–“/æ•¸å€¼ç¯„åœä½¿ç”¨ range æŸ¥è©¢)
            5. Support multi-index searches with flexible patterns (æ”¯æ´å½ˆæ€§æ¨¡å¼çš„å¤šç´¢å¼•æœå°‹)
            6. Automatically determine appropriate field names and values (è‡ªå‹•åˆ¤æ–·é©ç•¶çš„æ¬„ä½åç¨±å’Œå€¼)
            
            Always use proper DSL syntax like the examples above when constructing queries.
            ç¸½æ˜¯ä½¿ç”¨ä¸Šè¿°ç¯„ä¾‹ä¸­çš„æ­£ç¢º DSL èªæ³•ä¾†æ§‹å»ºæŸ¥è©¢ã€‚
            
            Time Range Guidelines (æ™‚é–“ç¯„åœæŒ‡å—):
            - For "past 24 hours" or "last day": use "now-24h" to "now"
            - For "past week": use "now-7d" to "now"  
            - For "past month": use "now-30d" to "now"
            - For "today": use "now/d" to "now"
            - For "yesterday": use "now-1d/d" to "now-1d/d+1d"
            
            ç•¶ç”¨æˆ¶è¦æ±‚æŸ¥è©¢ç‰¹å®šæ™‚é–“ç¯„åœæ™‚ï¼Œç›´æ¥ä½¿ç”¨ OpenSearch çš„ç›¸å°æ™‚é–“èªæ³•ï¼Œ
            ä¸éœ€è¦è©¢å•ç•¶å‰æ™‚é–“ã€‚ä½¿ç”¨ "now" ç›¸å°æ™‚é–“è¡¨é”å¼ã€‚""",
            server_names=["opensearch"],
        )

        async with opensearch_agent:
            logger.info("opensearch_searcher: Connected to server, calling list_tools...")
            result = await opensearch_agent.list_tools()
            logger.info("Tools available:", data=result.model_dump())

            llm = await opensearch_agent.attach_llm(GoogleAugmentedLLM)
            time_parser = TimeParser()

            # Interactive search loop
            print("\n=== OpenSearch è³‡å®‰äº‹ä»¶åˆ†æç³»çµ± å·²å•Ÿå‹• ===")
            print("ğŸ” è«‹è¼¸å…¥æ‚¨çš„æœå°‹æŸ¥è©¢ï¼Œè¼¸å…¥ 'quit' é€€å‡º")
            print("ğŸ“‹ ç³»çµ±æœƒè‡ªå‹•ç”Ÿæˆè©³ç´°çš„è³‡å®‰äº‹ä»¶åˆ†æå ±å‘Š")
            print("\nğŸ’¡ æŸ¥è©¢å»ºè­°:")
            print("   â€¢ äº‹ä»¶æŸ¥è©¢: 'authentication éå»24å°æ™‚', 'ç™»å…¥å¤±æ•— éå»7å¤©'")
            print("   â€¢ æ™‚é–“ç¯„åœ: 'éå»24å°æ™‚', 'æ˜¨å¤©', '2025-07-01 åˆ° 2025-07-10'")
            print("   â€¢ ç‰¹å®šäº‹ä»¶: 'event.category:authentication', 'failed login'")
            print("   â€¢ ä½¿ç”¨è€…æŸ¥è©¢: 'username:eagle_tseng éå»1é€±'")
            print("-" * 55)
            
            while True:
                try:
                    user_query = input("\nğŸ” è«‹è¼¸å…¥æœå°‹æŸ¥è©¢: ").strip()
                    
                    if user_query.lower() in ['quit', 'exit', 'é€€å‡º']:
                        print("æ„Ÿè¬ä½¿ç”¨ OpenSearch Agent!")
                        break
                    
                    if not user_query:
                        print("è«‹è¼¸å…¥æœ‰æ•ˆçš„æœå°‹æŸ¥è©¢")
                        continue
                    
                    print(f"\nâ³ æ­£åœ¨åŸ·è¡Œæœå°‹: {user_query}")
                    
                    # æª¢æŸ¥æ˜¯å¦ç‚ºçµ•å°æ™‚é–“å€é–“æŸ¥è©¢
                    if 'åˆ°' in user_query or ' to ' in user_query.lower():
                        # è™•ç†çµ•å°æ™‚é–“å€é–“
                        parts = re.split(r'åˆ°|to', user_query, flags=re.IGNORECASE)
                        if len(parts) == 2:
                            start_time = parts[0].strip()
                            end_time = parts[1].strip()
                            
                            # å˜—è©¦è§£æçµ•å°æ™‚é–“
                            time_range = time_parser.parse_absolute_time(start_time, end_time)
                            if time_range:
                                print(f"â° æª¢æ¸¬åˆ°æ™‚é–“å€é–“: {time_range['description']}")
                                enhanced_query = f"""åŸ·è¡Œ OpenSearch æŸ¥è©¢ï¼ŒåŒ…å«æ™‚é–“ç¯„åœé™åˆ¶ï¼š
                                åŸå§‹æŸ¥è©¢: {user_query}
                                æ™‚é–“ç¯„åœ: {{'range': {{'@timestamp': {{'gte': '{time_range['gte']}', 'lte': '{time_range['lte']}'}}}}}}
                                
                                é‡è¦ï¼šè«‹å¯¦éš›ä½¿ç”¨opensearch_search_logs_advancedå·¥å…·ä¾†åŸ·è¡Œæ­¤DSLæŸ¥è©¢ï¼Œä¸è¦åªå›æ‡‰æŸ¥è©¢èªæ³•ã€‚"""
                            else:
                                print("âš ï¸ æ™‚é–“æ ¼å¼ç„¡æ³•è§£æï¼Œå°‡ä½¿ç”¨åŸå§‹æŸ¥è©¢")
                                enhanced_query = f"""Execute search query in OpenSearch using available MCP tools: {user_query}

                                    é‡è¦ï¼šè«‹å¯¦éš›ä½¿ç”¨ä»¥ä¸‹å…¶ä¸­ä¸€å€‹OpenSearch MCPå·¥å…·ä¾†åŸ·è¡Œæœå°‹ï¼š
                                    1. opensearch_search_logs_by_keyword - ç”¨æ–¼é—œéµå­—æœå°‹  
                                    2. opensearch_search_logs_advanced - ç”¨æ–¼è¤‡é›œçš„DSLæŸ¥è©¢
                                    3. opensearch_list_log_indices - åˆ—å‡ºå¯ç”¨çš„ç´¢å¼•

                                    ä¸è¦åªå›æ‡‰æŸ¥è©¢èªæ³•ï¼Œè«‹å¯¦éš›èª¿ç”¨å·¥å…·ä¸¦è¿”å›æœå°‹çµæœã€‚"""
                        else:
                            enhanced_query = f"Execute search query in OpenSearch: {user_query}"
                    else:
                        # ä½¿ç”¨æ™‚é–“è§£æå™¨åˆ†ææŸ¥è©¢
                        time_aware_prompt = create_time_aware_prompt(user_query, time_parser)
                        enhanced_query = f"""Execute search query in OpenSearch using available MCP tools: {time_aware_prompt}

                            **åŸ·è¡Œæœå°‹æŸ¥è©¢ï¼š**
                            ä½¿ç”¨è€…æŸ¥è©¢: "{user_query}"
                            
                            è«‹ä½¿ç”¨ opensearch_search_logs_advanced å·¥å…·åŸ·è¡Œæœå°‹ï¼š
                            - è‡ªå‹•åˆ¤æ–·åˆé©çš„ç´¢å¼•æ¨¡å¼ï¼ˆå¯æœå°‹å¤šå€‹ç´¢å¼•ï¼‰
                            - æ ¹æ“šä½¿ç”¨è€…æŸ¥è©¢å…§å®¹æ§‹å»ºé©ç•¶çš„ DSL æŸ¥è©¢
                            - æ”¯æ´æœå°‹ä»»ä½•æ¬„ä½å’Œå€¼
                            - è«‹ç›´æ¥åŸ·è¡Œæœå°‹ä¸¦è¿”å›å¯¦éš›çµæœï¼Œä¸è¦åªæä¾›æŸ¥è©¢èªæ³•

                            è«‹ç«‹å³èª¿ç”¨å·¥å…·ä¸¦è¿”å›å¯¦éš›çš„æœå°‹çµæœã€‚"""
                    
                    # Execute search query
                    result = await llm.generate_str(message=enhanced_query)
                    logger.info(f"Search result for '{user_query}': {result}")
                    print(f"\nğŸ“Š æœå°‹çµæœ:\n{result}")
                    
                    # æª¢æŸ¥æ˜¯å¦ç‚ºç„¡æ•ˆçš„æœå°‹çµæœï¼ˆåªæœ‰æŸ¥è©¢èªæ³•è€Œæ²’æœ‰å¯¦éš›æ•¸æ“šï¼‰
                    # æ›´ç²¾ç¢ºçš„æª¢æ¸¬ï¼šåªæœ‰ç•¶çµæœåŒ…å«å·¥å…·èª¿ç”¨èªæ³•ä½†æ²’æœ‰å¯¦éš›æ•¸æ“šæ™‚æ‰è­¦å‘Š
                    has_tool_syntax = any(keyword in result.lower() for keyword in [
                        'tool_code', 'tool_name', 'tool_input', '```json', 'å¥½çš„ï¼Œæˆ‘å°‡ä½¿ç”¨'
                    ])
                    
                    has_actual_data = any(indicator in result.lower() for indicator in [
                        'hits', 'total', '_source', 'timestamp', '_id', 'found', 'documents', 'records'
                    ])
                    
                    is_query_only = has_tool_syntax and not has_actual_data
                    
                    if is_query_only:
                        print("âš ï¸ æª¢æ¸¬åˆ°æŸ¥è©¢èªæ³•ä½†ç„¡å¯¦éš›æœå°‹çµæœï¼Œå¯èƒ½æ˜¯OpenSearchæœå‹™å™¨æœªé€£æ¥")
                        print("ğŸ’¡ å»ºè­°ï¼šè«‹ç¢ºèªOpenSearch MCPæœå‹™å™¨æ˜¯å¦æ­£åœ¨é‹è¡Œ")
                    
                    # Generate structured summary only if we got results
                    if result and len(result.strip()) > 0:
                        try:
                            # Debug: æª¢æŸ¥å‚³å…¥LLMçš„åƒæ•¸
                            structured_message = f"""ã€é‡è¦ã€‘é€™æ˜¯è³‡æ–™åˆ†æéšæ®µï¼Œè«‹åš´æ ¼åŸºæ–¼å·²æœ‰çš„æœå°‹çµæœé€²è¡Œåˆ†æï¼Œçµ•å°ä¸è¦å†æ¬¡åŸ·è¡Œä»»ä½•å·¥å…·æˆ–æœå°‹ï¼š

                            åŸå§‹æŸ¥è©¢: {user_query}
                            å·²å®Œæˆçš„æœå°‹çµæœ: {result}

                            **æ‚¨çš„ä»»å‹™ï¼šåƒ…é€²è¡Œè³‡æ–™åˆ†æï¼Œä¸åŸ·è¡Œä»»ä½•å·¥å…·**
                            è«‹åŸºæ–¼ä¸Šè¿°æœå°‹çµæœæå–ä»¥ä¸‹è³‡è¨Šï¼š
                            - total_hits: å¾çµæœä¸­æå–çš„å¯¦éš›è¨˜éŒ„ç¸½æ•¸
                            - event_time: å¾æ—¥èªŒä¸­æå–çš„äº‹ä»¶æ™‚é–“
                            - event_type: å¾æ—¥èªŒä¸­æå–çš„äº‹ä»¶é¡å‹
                            - severity: åŸºæ–¼äº‹ä»¶å…§å®¹è©•ä¼°åš´é‡æ€§
                            - username: å¾æ—¥èªŒä¸­æå–çš„ä½¿ç”¨è€…åç¨±ï¼ˆå¦‚ç„¡å‰‡ç‚º"ç„¡è³‡æ–™"ï¼‰
                            - hostname: å¾æ—¥èªŒä¸­æå–çš„ä¸»æ©Ÿåç¨±
                            - host_ip: å¾æ—¥èªŒä¸­æå–çš„IPåœ°å€ï¼ˆå¦‚ç„¡å‰‡ç‚º"ç„¡è³‡æ–™"ï¼‰
                            - description: åŸºæ–¼æœå°‹çµæœçš„ç°¡è¦æè¿°
                            - recommended_actions: åŸºæ–¼åˆ†æçµæœçš„å»ºè­°è¡Œå‹•
                            - log_samples: å¾æœå°‹çµæœä¸­æå–çš„ä»£è¡¨æ€§æ—¥èªŒå…§å®¹

                            **åš´æ ¼ç¦æ­¢ï¼š**
                            - ä¸è¦åŸ·è¡Œä»»ä½• OpenSearch å·¥å…·
                            - ä¸è¦é‡æ–°æœå°‹ä»»ä½•è³‡æ–™
                            - ä¸è¦ç·¨é€ ä»»ä½•è³‡æ–™
                            - åªèƒ½åˆ†æå·²æä¾›çš„æœå°‹çµæœ"""
                                                        
                            print(f"\nğŸ” Debug - å‚³å…¥LLMçš„messageé•·åº¦: {len(structured_message)}")
                            print(f"ğŸ” Debug - response_modelé¡å‹: {SecurityEventReport}")
                            print(f"ğŸ” Debug - åŸå§‹æœå°‹çµæœé•·åº¦: {len(result)}")
                            
                            structured_result = await llm.generate_structured(
                                message=structured_message,
                                response_model=SecurityEventReport,
                            )
                            
                            # Debug: æª¢æŸ¥è¿”å›çš„çµæœ
                            print(f"\nğŸ” Debug - structured_resulté¡å‹: {type(structured_result)}")
                            print(f"ğŸ” Debug - structured_resultæ˜¯å¦ç‚ºNone: {structured_result is None}")
                            
                            # æª¢æŸ¥æ˜¯å¦ç‚ºValidationError
                            if hasattr(structured_result, 'errors'):
                                print(f"âŒ æª¢æ¸¬åˆ°ValidationError: {structured_result}")
                                print(f"ğŸ” Debug - ValidationErrorè©³ç´°ä¿¡æ¯: {structured_result.errors()}")
                                raise structured_result
                            elif structured_result and isinstance(structured_result, SecurityEventReport):
                                print(f"ğŸ” Debug - structured_resultå…§å®¹: {structured_result}")
                                print(f"ğŸ” Debug - queryå±¬æ€§: {hasattr(structured_result, 'query')}")
                                print(f"ğŸ” Debug - total_hitså±¬æ€§: {hasattr(structured_result, 'total_hits')}")
                                
                                # é¡¯ç¤ºæ–°æ ¼å¼çš„è³‡å®‰äº‹ä»¶åˆ†æå ±å‘Š
                                description = getattr(structured_result, 'description', 'ç„¡æè¿°')
                                total_hits = getattr(structured_result, 'total_hits', 0)
                                severity = getattr(structured_result, 'severity', 'ä¸­')
                                
                                # ç²å–å®‰å…¨ç‹€æ…‹æŒ‡ç¤ºå™¨
                                status_indicator = get_security_status_indicator(severity, total_hits)
                                
                                # æª¢æŸ¥æ˜¯å¦ç‚ºæŸ¥è©¢æœªåŸ·è¡Œçš„æƒ…æ³
                                if total_hits == 0 and any(keyword in description for keyword in ['æŸ¥è©¢æœªåŸ·è¡Œ', 'ç„¡è³‡æ–™', 'ç„¡å¯¦éš›æ•¸æ“š']):
                                    print(f"\n[ âš ï¸ æŸ¥è©¢å¤±æ•— ]")
                                    print(f"ğŸ“„ æ‘˜è¦ï¼šæŸ¥è©¢æœªæˆåŠŸåŸ·è¡Œ")
                                    print(f"ğŸ“‹ åŸå› ï¼š{description}")
                                    print(f"\nğŸ’¡ å»ºè­°æª¢æŸ¥ï¼š")
                                    print(f"â€¢ OpenSearch MCPæœå‹™å™¨æ˜¯å¦å•Ÿå‹•")
                                    print(f"â€¢ ç¶²è·¯é€£æ¥æ˜¯å¦æ­£å¸¸")
                                    print(f"â€¢ ç´¢å¼•åç¨±æˆ–æŸ¥è©¢èªæ³•æ˜¯å¦æ­£ç¢º")
                                else:
                                    # æ­£å¸¸çš„å®‰å…¨å ±å‘Šæ ¼å¼
                                    print(f"\n[ {status_indicator} ]")
                                    print(f"ğŸ“„ æ‘˜è¦ï¼š{description}")
                                    print(f"ğŸ•’ æ™‚é–“ï¼š{getattr(structured_result, 'event_time', 'æœªçŸ¥æ™‚é–“')}")
                                    print(f"ğŸ‘¤ ä½¿ç”¨è€…ï¼š{getattr(structured_result, 'username', 'æœªçŸ¥ä½¿ç”¨è€…')}")
                                    print(f"ğŸ’» ä¸»æ©Ÿï¼š{getattr(structured_result, 'hostname', 'æœªçŸ¥ä¸»æ©Ÿ')}")
                                    print(f"ğŸŒ IPï¼š{getattr(structured_result, 'host_ip', 'æœªçŸ¥IP')}")
                                    
                                    # å»ºè­°è¡Œå‹•
                                    actions = getattr(structured_result, 'recommended_actions', [])
                                    if actions and actions != ['æŸ¥è©¢æœªåŸ·è¡Œ'] and actions != ['ç„¡è³‡æ–™']:
                                        # åˆä½µæ‰€æœ‰å»ºè­°ç‚ºä¸€è¡Œ
                                        combined_actions = "ï¼Œ".join(actions)
                                        print(f"âœ… å»ºè­°ï¼š{combined_actions}")
                                    
                                    # å®Œæ•´æ—¥èªŒå±•é–‹åŠŸèƒ½
                                    log_samples = getattr(structured_result, 'log_samples', [])
                                    if log_samples and log_samples != ['æŸ¥è©¢æœªåŸ·è¡Œ'] and log_samples != ['ç„¡è³‡æ–™']:
                                        print(f"\n[ ğŸ” å±•é–‹å®Œæ•´æ—¥èªŒ â–¼ ]")
                                        # æœ€å¤šé¡¯ç¤º3ç­†æ—¥èªŒ
                                        max_logs = min(3, len(log_samples))
                                        for i, log in enumerate(log_samples[:max_logs]):
                                            print(f"\n--- æ—¥èªŒ {i+1}/{max_logs} ---")
                                            formatted_log = format_log_sample(log)
                                            print(formatted_log)
                                        
                                        if len(log_samples) > 3:
                                            print(f"\n... é‚„æœ‰ {len(log_samples) - 3} ç­†æ—¥èªŒ (å·²çœç•¥)")
                                
                                print(f"\nğŸ“Š ç¸½è¨ˆï¼š{total_hits} ç­†è¨˜éŒ„")
                            else:
                                print(f"âš ï¸ structured_resulté¡å‹ä¸æ­£ç¢ºæˆ–ç‚ºNone: {type(structured_result)}")
                                print(f"ğŸ” Debug - å…§å®¹: {structured_result}")
                                
                            logger.info(f"Structured search result: {structured_result}")
                        except Exception as e:
                            error_msg = str(e) if hasattr(e, '__str__') else type(e).__name__
                            print(f"âš ï¸ çµæ§‹åŒ–æ‘˜è¦ç”Ÿæˆå¤±æ•—: {error_msg}")
                            
                            # ç‰¹åˆ¥è™•ç†ValidationError
                            if hasattr(e, 'errors'):
                                print(f"ğŸ” Debug - ValidationErrorè©³ç´°ä¿¡æ¯: {e.errors()}")
                            
                            logger.error(f"Structured summary generation failed: {error_msg}", exc_info=True)
                    else:
                        print("âš ï¸ æ²’æœ‰ç²å¾—æœå°‹çµæœï¼Œè·³éçµæ§‹åŒ–æ‘˜è¦")
                    
                except KeyboardInterrupt:
                    print("\n\næ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨é€€å‡º...")
                    break
                except Exception as e:
                    logger.error(f"åŸ·è¡Œæœå°‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    print(f"âŒ æœå°‹å¤±æ•—: {e}")


async def demo_usage():
    """Demo mode with predefined queries"""
    async with app.run() as agent_app:
        logger = agent_app.logger
        
        opensearch_agent = Agent(
            name="opensearch_searcher", 
            instruction="""You are an OpenSearch query agent. Execute searches and return results in a clear format.""",
            server_names=["opensearch"],
        )

        async with opensearch_agent:
            llm = await opensearch_agent.attach_llm(GoogleAugmentedLLM)
            
            # Demo queries
            demo_queries = [
                "search for documents containing 'machine learning'",
                "find all entries with status='active' and timestamp from last week",
                "lookup user profiles where role='admin'"
            ]
            
            for query in demo_queries:
                print(f"\nğŸ” DemoæŸ¥è©¢: {query}")
                result = await llm.generate_str(message=f"Execute OpenSearch query: {query}")
                logger.info(f"Demo result: {result}")
                print(f"ğŸ“Š çµæœ: {result}")


if __name__ == "__main__":
    import sys
    
    start = time.time()
    
    # Check for different modes
    if len(sys.argv) > 1:
        mode = sys.argv[1]
        if mode == "test":
            print("ğŸ”§ å•Ÿå‹•é€£ç·šæ¸¬è©¦æ¨¡å¼...")
            asyncio.run(test_connection())
        elif mode == "demo":
            print("ğŸš€ å•Ÿå‹• Demo æ¨¡å¼...")
            asyncio.run(demo_usage())
        else:
            print(f"æœªçŸ¥æ¨¡å¼: {mode}")
            print("å¯ç”¨æ¨¡å¼: test, demo, æˆ–ä¸æŒ‡å®šåƒæ•¸é€²å…¥äº’å‹•æ¨¡å¼")
    else:
        print("ğŸš€ å•Ÿå‹•äº’å‹•æ¨¡å¼...")
        asyncio.run(example_usage())
    
    end = time.time()
    t = end - start
    print(f"\nTotal run time: {t:.2f}s")